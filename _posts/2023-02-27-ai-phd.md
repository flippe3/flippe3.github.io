---
layout: post
title: "Machine Learning PhD"
tags: machine learning, phd, neuroscience, reinforcement learning
---
## Intro
Currently I think it would be fair to divide artificial intelligence into a four subfields. Of course there are many others but these are the ones that most closely relates to me currently. 

## Generative machine learning
2022 was an absolutely amazing year for machine learning, not only did we get chat-GPT in the end of the year but we also got a bunch of different diffusion models. I don't think any of these ideas are breakthrough research ideas but they certainly made a mark on how the public views AI. Without understanding what DALL-E and chat-GPT are doing under the hood this technology seems absolutely magical and its amazing to see what you can create from very simple prompts. Yet I don't see a way for this to scale to intelligence (bold statement before seeing GPT-4). I think these models are cool and they will improve and assist us in a lot of different parts of life but they will not suddenly start pumping out Nobel prize worthy research articles. These models are not intelligent and they have no real understanding. These are generative models that are trained to become experts at predicting what a human would write as a continuation of the prompt. 

However I do think we will see a lot of promising research in this direction since this will generate lots of profit for companies. Yet I do only see this lasting for ~2 years then we will be limited by the very notion of generative models. 

## Reinforcement learning (RL) 
RL is great, its probably the most human-like approach to creating intelligent systems that we have seen in AI. Its doing trial-and-error learning to improve its model and therefore learning to solve all kinds of problems. This is very much to be compared to how humans learn. The biggest problem of RL is that it doesn't really work. Supervised machine learning works pretty well as long as we have enough data, then we can modify millions of parameters until they seem to appropriately be able to classify images or whatever supervised problem you would like to solve. The problem in reinforcement learning is that the trial and error learning is based on the previous step. So when you have a vast state space, it is very difficult to make an RL algorithm learn efficiently because you might only get to see that certain state in one of a million trials. Conclusion: RL is great but nobody has really gotten it to do anything truly "generally" intelligent. When RL is given enough time to train it can learn to solve one task very well but can it generalize from that? No.

## Brain emulation (SNN)
Another approach could be that of spiking neural networks which is a type of machine learning where we try to perfectly simulate what a human brain is doing in hopes of just emulating the brain and therefore achieve intelligence. This research is very much based in the "the only proof of intelligence that we have is the human mind so emulating that would guarantee intelligence". Yet this approach has not gotten very far and when deep learning started to work that quickly dominated the industry of machine learning since it could actually make profits. Therefore it is difficult to compare this to that of more traditional machine learning methods of artificial neural networks. When we look back at history though the wright brothers did not fly by emulating a bird flying.

## Brain understanding
Okay, but instead of directly trying to build a brain or an algorithm. What if we start with the first step of understanding the human brain. This is very much in the field of neuroscience and a lot of neuroscience and AI is starting to merge. While neuroscientists are studying the brain to try to understand what happens AI scientists would like to try to build similar concepts that we see in the brain. While the brain is rather difficult to understand so perhaps the easiest way to understand what the brain is doing would be to build an AI that could understand it for us? 

## Discussion
I've been asked if I want to pursue a PhD in inner speech recognition which would slot into brain understanding, I would use machine learning methods to try to understand what the brain is doing to produce thought. This is very much a PhD in neuroscience and machine learning, so now I'm a bit lost. As I see it, either I can choose to work or research in generative machine learning which probably has the most jobs and the most money, or I could give RL a shot and lose my mind for four years trying to make RL actually work which still could be an intractable problem. LTU is doing a lot of research in SNN and brain emulation so I could possibly also get a PhD position in that but I don't think that building a brain by simulating it in neuromorphic hardware is remotely close to working. So lastly I have to choose if I want to settle for understanding the brain, perhaps I could learn more by just studying the brain using machine learning for four years than I could in any other field. 
